{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "798e800a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da456836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "301fe87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print (use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec83f3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__CUDNN VERSION: 8200\n",
      "__Number CUDA Devices: 1\n",
      "__CUDA Device Name: NVIDIA GeForce RTX 3070 Ti\n",
      "__CUDA Device Total Memory [GB]: 8.589410304\n"
     ]
    }
   ],
   "source": [
    "if use_cuda:\n",
    "    print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "    print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "    print('__CUDA Device Name:',torch.cuda.get_device_name(0))\n",
    "    print('__CUDA Device Total Memory [GB]:',torch.cuda.get_device_properties(0).total_memory/1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "314bbb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load teacher model\n",
      "Create student model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "###### CREATE MODEL ######\n",
    "max_seq_length = 64\n",
    "train_batch_size = 32\n",
    "\n",
    "# Load teacher model\n",
    "print(\"Load teacher model\")\n",
    "teacher_model = SentenceTransformer('stsb-roberta-base-v2')\n",
    "\n",
    "# Create student model\n",
    "print(\"Create student model\")\n",
    "word_embedding_model = models.Transformer(\"xlm-roberta-base\")\n",
    "\n",
    "# Apply mean pooling to get one fixed sized sentence vector\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
    "                               pooling_mode_mean_tokens=True,\n",
    "                               pooling_mode_cls_token=False,\n",
    "                               pooling_mode_max_tokens=False)\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model], device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e4de289",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read Datasets ####\n",
    "\n",
    "df1 = pd.read_csv('C:/Users/USER/Desktop/Knowledge Distillaation/1 Datasets/Compiled Datasets/EN_TL_compiled_400k.csv')\n",
    "df2 = pd.read_csv('C:/Users/USER/Desktop/Knowledge Distillaation/1 Datasets/Compiled Datasets/STS_TL_400k.csv')\n",
    "#df3 = pd.read_csv('datasets/translate_s2.txt', delimiter = '\\t', encoding = 'unicode_escape')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d96ab69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tl</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ayon naman kay Bayan Muna Rep. Carlos Zarate, ...</td>\n",
       "      <td>According to Bayan Muna Rep. Carlos Zarate, Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ayon naman sa Philippine Embassy sa Washington...</td>\n",
       "      <td>According to the Philippine Embassy in Washing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paano maipagtatanggol ng mga ordinaryong mamam...</td>\n",
       "      <td>How do ordinary citizens defend themselves fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SM by the bay</td>\n",
       "      <td>SM by the bay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MANILA, Philippines - Inirekomenda ng Departme...</td>\n",
       "      <td>Manila, Philippines - The Department of Interi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399995</th>\n",
       "      <td>\"The President will discuss with Japanese Prim...</td>\n",
       "      <td>\"The President Will Discuss With Japanese Prim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399996</th>\n",
       "      <td>Matatandaang idiniskwalipika ng Commission on ...</td>\n",
       "      <td>The Commission on Elections (COMELEC) (COMELEC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399997</th>\n",
       "      <td>Dahil sa huling score, inilarawan ng Heritage ...</td>\n",
       "      <td>Due to the last score, the Heritage Foundation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399998</th>\n",
       "      <td>MANILA, Philippines -- Wala umanong karapatan ...</td>\n",
       "      <td>Manila, Philippines - The Government of Puerto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399999</th>\n",
       "      <td>Malinaw aniya na nakasaad sa Section 5, Articl...</td>\n",
       "      <td>It is clearly stated in Section 5, Article 99 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       tl  \\\n",
       "0       Ayon naman kay Bayan Muna Rep. Carlos Zarate, ...   \n",
       "1       Ayon naman sa Philippine Embassy sa Washington...   \n",
       "2       Paano maipagtatanggol ng mga ordinaryong mamam...   \n",
       "3                                           SM by the bay   \n",
       "4       MANILA, Philippines - Inirekomenda ng Departme...   \n",
       "...                                                   ...   \n",
       "399995  \"The President will discuss with Japanese Prim...   \n",
       "399996  Matatandaang idiniskwalipika ng Commission on ...   \n",
       "399997  Dahil sa huling score, inilarawan ng Heritage ...   \n",
       "399998  MANILA, Philippines -- Wala umanong karapatan ...   \n",
       "399999  Malinaw aniya na nakasaad sa Section 5, Articl...   \n",
       "\n",
       "                                                       en  \n",
       "0       According to Bayan Muna Rep. Carlos Zarate, Ch...  \n",
       "1       According to the Philippine Embassy in Washing...  \n",
       "2       How do ordinary citizens defend themselves fro...  \n",
       "3                                          SM by the bay   \n",
       "4       Manila, Philippines - The Department of Interi...  \n",
       "...                                                   ...  \n",
       "399995  \"The President Will Discuss With Japanese Prim...  \n",
       "399996  The Commission on Elections (COMELEC) (COMELEC...  \n",
       "399997  Due to the last score, the Heritage Foundation...  \n",
       "399998  Manila, Philippines - The Government of Puerto...  \n",
       "399999  It is clearly stated in Section 5, Article 99 ...  \n",
       "\n",
       "[400000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62307383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Hindi ko ugali ang mamulitika; mas gusto kong...</td>\n",
       "      <td>Ito ang dineklara ni Atty. Romulo Macalintal, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ayon naman kay Bayan Muna Rep. Carlos Zarate, ...</td>\n",
       "      <td>Dating itinutulak ni Duterte ang pagbabago ng ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ayon naman sa Philippine Embassy sa Washington...</td>\n",
       "      <td>Ayon sa NBI, hindi umano siyento por siyentong...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paano maipagtatanggol ng mga ordinaryong mamam...</td>\n",
       "      <td>\"Nakasaad sa R.A. 9009 na dapat mayroong land ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SM by the bay</td>\n",
       "      <td>Kabilang sa mga sumali sa programang ito ang m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419995</th>\n",
       "      <td>2p.m. Arellano University vs Hog's Breath Cafe</td>\n",
       "      <td>Inirekomenda sa Pangulo ni Albay Rep. Joey Sal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419996</th>\n",
       "      <td>Jason Davee: We rather want the senate head to...</td>\n",
       "      <td>Sabi naman ni Eberl, gumagana pa rin naman uma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419997</th>\n",
       "      <td>Ipinatupad ang liquid ban sa mga istasyon ng M...</td>\n",
       "      <td>Gumastos naman ng P11.587 milyon ang mga contr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419998</th>\n",
       "      <td>Team Standings: zArellano (13-4); zSan Beda (1...</td>\n",
       "      <td>z - Final Four twice-to-beat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419999</th>\n",
       "      <td>Batay sa nakalap na report mula sa tanggapan n...</td>\n",
       "      <td>Hindi umano na-impress si Pangulong Rodrigo Du...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       s1  \\\n",
       "0       \"Hindi ko ugali ang mamulitika; mas gusto kong...   \n",
       "1       Ayon naman kay Bayan Muna Rep. Carlos Zarate, ...   \n",
       "2       Ayon naman sa Philippine Embassy sa Washington...   \n",
       "3       Paano maipagtatanggol ng mga ordinaryong mamam...   \n",
       "4                                           SM by the bay   \n",
       "...                                                   ...   \n",
       "419995     2p.m. Arellano University vs Hog's Breath Cafe   \n",
       "419996  Jason Davee: We rather want the senate head to...   \n",
       "419997  Ipinatupad ang liquid ban sa mga istasyon ng M...   \n",
       "419998  Team Standings: zArellano (13-4); zSan Beda (1...   \n",
       "419999  Batay sa nakalap na report mula sa tanggapan n...   \n",
       "\n",
       "                                                       s2  label  \n",
       "0       Ito ang dineklara ni Atty. Romulo Macalintal, ...      1  \n",
       "1       Dating itinutulak ni Duterte ang pagbabago ng ...      0  \n",
       "2       Ayon sa NBI, hindi umano siyento por siyentong...      1  \n",
       "3       \"Nakasaad sa R.A. 9009 na dapat mayroong land ...      1  \n",
       "4       Kabilang sa mga sumali sa programang ito ang m...      1  \n",
       "...                                                   ...    ...  \n",
       "419995  Inirekomenda sa Pangulo ni Albay Rep. Joey Sal...      1  \n",
       "419996  Sabi naman ni Eberl, gumagana pa rin naman uma...      1  \n",
       "419997  Gumastos naman ng P11.587 milyon ang mga contr...      1  \n",
       "419998                       z - Final Four twice-to-beat      0  \n",
       "419999  Hindi umano na-impress si Pangulong Rodrigo Du...      1  \n",
       "\n",
       "[420000 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aff508bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.datasets import ParallelSentencesDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import SentencesDataset, losses, evaluation, readers\n",
    "\n",
    "\n",
    "###### Load train sets ######\n",
    "\n",
    "train_reader = ParallelSentencesDataset(student_model=model, teacher_model=teacher_model)\n",
    "train_reader.add_dataset(df1.values.tolist())\n",
    "#load_data('translate_s1.txt', encoding= 'unicode_escape')\n",
    "train_dataloader = DataLoader(train_reader, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.MSELoss(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1aaa729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd62bb6540c645c586bc76d7b906fccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###### Load test sets Mean Squared Error (MSE) measures ######\n",
    "\n",
    "evaluators = []\n",
    "\n",
    "test_mse = evaluation.MSEEvaluator(df1['en'].values.tolist(),df1['tl'].values.tolist(), teacher_model=teacher_model, batch_size=train_batch_size, show_progress_bar=True, write_csv = True)\n",
    "evaluators.append(test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50fe240b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Load dev sets for Semantic Textual Similarity (STS) data ######\n",
    "\n",
    "evaluator_sts = evaluation.EmbeddingSimilarityEvaluator(df2['s1'], df2['s2'], df2['label'], batch_size=train_batch_size, show_progress_bar=True, write_csv=True)\n",
    "evaluators.append(evaluator_sts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec09e236",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_trans = evaluation.TranslationEvaluator(df1['en'].values.tolist(),df1['tl'].values.tolist(), show_progress_bar = True, batch_size = train_batch_size, write_csv=True)\n",
    "evaluators.append(evaluator_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fe6459e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca4c489c6d3470aa1bb6ae60f6d3be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4651de155384eae922825613b891aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/6087 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:537: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_new.cpp:201.)\n",
      "  labels = torch.tensor(labels).to(self._target_device)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 734.00 MiB (GPU 0; 8.00 GiB total capacity; 4.64 GiB already allocated; 0 bytes free; 5.97 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13576/1907256266.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0moutput_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"output/model-\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoday\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%Y-%m-%d\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m model.fit(train_objectives=[(train_dataloader, train_loss)],\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mevaluator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequentialEvaluator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmain_score_function\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit)\u001b[0m\n\u001b[0;32m    711\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m                         \u001b[0mloss_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 713\u001b[1;33m                         \u001b[0mloss_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    714\u001b[0m                         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 734.00 MiB (GPU 0; 8.00 GiB total capacity; 4.64 GiB already allocated; 0 bytes free; 5.97 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "###### Train model ######\n",
    "#torch.cuda.empty_cache()\n",
    "import datetime\n",
    "\n",
    "output_path = \"output/model-\" + datetime.date.today().strftime(\"%Y-%m-%d\")\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "        evaluator=evaluation.SequentialEvaluator(evaluators, main_score_function=lambda scores: scores[-1]),\n",
    "        epochs=10,\n",
    "        evaluation_steps=1000,\n",
    "        warmup_steps=10000,\n",
    "        scheduler='warmupconstant',\n",
    "        output_path=output_path,\n",
    "        save_best_model=True,\n",
    "        optimizer_params= {'lr': 2e-5, 'eps': 1e-6, 'correct_bias': False}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6cd96f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 1            |        cudaMalloc retries: 1         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |    4741 MB |    5685 MB |   17476 GB |   17471 GB |\\n|       from large pool |    4739 MB |    5674 MB |   17408 GB |   17403 GB |\\n|       from small pool |       2 MB |      34 MB |      67 GB |      67 GB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |    4741 MB |    5685 MB |   17476 GB |   17471 GB |\\n|       from large pool |    4739 MB |    5674 MB |   17408 GB |   17403 GB |\\n|       from small pool |       2 MB |      34 MB |      67 GB |      67 GB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |    6112 MB |    6474 MB |    6474 MB |  370688 KB |\\n|       from large pool |    6100 MB |    6434 MB |    6434 MB |  342016 KB |\\n|       from small pool |      12 MB |      40 MB |      40 MB |   28672 KB |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |    1370 MB |    1411 MB |   16467 GB |   16466 GB |\\n|       from large pool |    1360 MB |    1404 MB |   16390 GB |   16389 GB |\\n|       from small pool |       9 MB |       9 MB |      77 GB |      77 GB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |    1000    |    1253    |    4002 K  |    4001 K  |\\n|       from large pool |     373    |     557    |    3010 K  |    3010 K  |\\n|       from small pool |     627    |     824    |     991 K  |     990 K  |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |    1000    |    1253    |    4002 K  |    4001 K  |\\n|       from large pool |     373    |     557    |    3010 K  |    3010 K  |\\n|       from small pool |     627    |     824    |     991 K  |     990 K  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |      95    |     127    |     127    |      32    |\\n|       from large pool |      89    |     107    |     107    |      18    |\\n|       from small pool |       6    |      20    |      20    |      14    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |     102    |     123    |    2243 K  |    2243 K  |\\n|       from large pool |      64    |      77    |    1790 K  |    1790 K  |\\n|       from small pool |      38    |      54    |     453 K  |     452 K  |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e245c974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5961180160"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.max_memory_allocated(device=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848b7d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833591d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.spatial\n",
    "\n",
    "#Corpus with example sentences\n",
    "corpusEN = df3['EN'][:20].values.tolist()\n",
    "corpusTL = df3['TL'][:20].values.tolist()\n",
    "\n",
    "corpusEN_embeddings = model.encode(corpusEN)\n",
    "corpusTL_embeddings = model.encode(corpusTL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea18f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = df1['EN'][88:89].values.tolist()\n",
    "query_embeddings = model.encode(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd470168",
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_n = 5\n",
    "\n",
    "for query, query_embedding in zip(queries, query_embeddings):\n",
    "    distances = scipy.spatial.distance.cdist([query_embedding], corpusEN_embeddings, \"cosine\")[0]\n",
    "    \n",
    "    results = zip(range(len(distances)), distances)\n",
    "    results = sorted(results, key=lambda x: x[1])\n",
    "    \n",
    "    print(\"\\n=======\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop 5 most similar sentences in corpus:\\n\")\n",
    "\n",
    "    for idx, distance in results[0:closest_n]:\n",
    "        print(corpusEN[idx].strip(), \"(Score: %.4f)\" % (1-distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff0afb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "queriesTL = df1['TL'][88:89].values.tolist()\n",
    "#queriesTL = ['gobyerno.']\n",
    "queryTL_embeddings = model.encode(queriesTL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a6a572",
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_n = 5\n",
    "for query, queryTL_embedding in zip(queriesTL, queryTL_embeddings):\n",
    "    distances = scipy.spatial.distance.cdist([queryTL_embedding], corpusTL_embeddings, \"cosine\")[0]\n",
    "    \n",
    "    results = zip(range(len(distances)), distances)\n",
    "    results = sorted(results, key=lambda x: x[1])\n",
    "    \n",
    "    print(\"\\n=======\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop 5 most similar sentences in corpus:\\n\")\n",
    "\n",
    "    for idx, distance in results[0:closest_n]:\n",
    "        print(corpusTL[idx].strip(), \"(Score: %.4f)\" % (1-distance))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d25f043",
   "metadata": {},
   "source": [
    "### after 100 epocs of training: Query Search Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4437204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.spatial\n",
    "\n",
    "#Corpus with example sentences\n",
    "corpusEN = df3['EN'][:20].values.tolist()\n",
    "corpusTL = df3['TL'][:20].values.tolist()\n",
    "\n",
    "with strategy.scope():\n",
    "    corpusEN_embeddings = model.encode(corpusEN)\n",
    "    corpusTL_embeddings = model.encode(corpusTL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d662593",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = df1['EN'][88:89].values.tolist()\n",
    "query_embeddings = model.encode(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b910d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_n = 5\n",
    "\n",
    "with strategy.scope():\n",
    "    for query, query_embedding in zip(queries, query_embeddings):\n",
    "        distances = scipy.spatial.distance.cdist([query_embedding], corpusEN_embeddings, \"cosine\")[0]\n",
    "    \n",
    "        results = zip(range(len(distances)), distances)\n",
    "        results = sorted(results, key=lambda x: x[1])\n",
    "    \n",
    "        print(\"\\n=======\\n\")\n",
    "        print(\"Query:\", query)\n",
    "        print(\"\\nTop 5 most similar sentences in corpus:\\n\")\n",
    "\n",
    "        for idx, distance in results[0:closest_n]:\n",
    "            print(corpusEN[idx].strip(), \"(Score: %.4f)\" % (1-distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c82325",
   "metadata": {},
   "outputs": [],
   "source": [
    "queriesTL = df1['TL'][88:89].values.tolist()\n",
    "#queriesTL = ['Balita tungkol sa transportasyon, gobyerno ng Pilipinas at iba pa.']\n",
    "queryTL_embeddings = model.encode(queriesTL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cbf953",
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_n = 5\n",
    "for query, queryTL_embedding in zip(queriesTL, queryTL_embeddings):\n",
    "    distances = scipy.spatial.distance.cdist([queryTL_embedding], corpusTL_embeddings, \"cosine\")[0]\n",
    "    \n",
    "    results = zip(range(len(distances)), distances)\n",
    "    results = sorted(results, key=lambda x: x[1])\n",
    "    \n",
    "    print(\"\\n=======\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop 5 most similar sentences in corpus:\\n\")\n",
    "\n",
    "    for idx, distance in results[0:closest_n]:\n",
    "        print(corpusTL[idx].strip(), \"(Score: %.4f)\" % (1-distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3a3dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
