{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "798e800a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "314bbb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load teacher model\n",
      "Create student model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "###### CREATE MODEL ######\n",
    "max_seq_length = 128\n",
    "train_batch_size = 64\n",
    "\n",
    "# Load teacher model\n",
    "print(\"Load teacher model\")\n",
    "teacher_model = SentenceTransformer('stsb-roberta-base-v2')\n",
    "\n",
    "# Create student model\n",
    "print(\"Create student model\")\n",
    "word_embedding_model = models.Transformer(\"xlm-roberta-base\")\n",
    "\n",
    "# Apply mean pooling to get one fixed sized sentence vector\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
    "                               pooling_mode_mean_tokens=True,\n",
    "                               pooling_mode_cls_token=False,\n",
    "                               pooling_mode_max_tokens=False)\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e4de289",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Read Datasets ####\n",
    "\n",
    "df1 = pd.read_csv('C:/Users/USER/Desktop/Knowledge Distillaation/1 Datasets/Compiled Datasets/EN_TL_compiled_400k.csv')\n",
    "df2 = pd.read_csv('C:/Users/USER/Desktop/Knowledge Distillaation/1 Datasets/Compiled Datasets/STS_TL_400k.csv')\n",
    "#df3 = pd.read_csv('datasets/translate_s2.txt', delimiter = '\\t', encoding = 'unicode_escape')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d96ab69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tl</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ayon naman kay Bayan Muna Rep. Carlos Zarate, ...</td>\n",
       "      <td>According to Bayan Muna Rep. Carlos Zarate, Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ayon naman sa Philippine Embassy sa Washington...</td>\n",
       "      <td>According to the Philippine Embassy in Washing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paano maipagtatanggol ng mga ordinaryong mamam...</td>\n",
       "      <td>How do ordinary citizens defend themselves fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SM by the bay</td>\n",
       "      <td>SM by the bay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MANILA, Philippines - Inirekomenda ng Departme...</td>\n",
       "      <td>Manila, Philippines - The Department of Interi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399995</th>\n",
       "      <td>\"The President will discuss with Japanese Prim...</td>\n",
       "      <td>\"The President Will Discuss With Japanese Prim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399996</th>\n",
       "      <td>Matatandaang idiniskwalipika ng Commission on ...</td>\n",
       "      <td>The Commission on Elections (COMELEC) (COMELEC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399997</th>\n",
       "      <td>Dahil sa huling score, inilarawan ng Heritage ...</td>\n",
       "      <td>Due to the last score, the Heritage Foundation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399998</th>\n",
       "      <td>MANILA, Philippines -- Wala umanong karapatan ...</td>\n",
       "      <td>Manila, Philippines - The Government of Puerto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399999</th>\n",
       "      <td>Malinaw aniya na nakasaad sa Section 5, Articl...</td>\n",
       "      <td>It is clearly stated in Section 5, Article 99 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       tl  \\\n",
       "0       Ayon naman kay Bayan Muna Rep. Carlos Zarate, ...   \n",
       "1       Ayon naman sa Philippine Embassy sa Washington...   \n",
       "2       Paano maipagtatanggol ng mga ordinaryong mamam...   \n",
       "3                                           SM by the bay   \n",
       "4       MANILA, Philippines - Inirekomenda ng Departme...   \n",
       "...                                                   ...   \n",
       "399995  \"The President will discuss with Japanese Prim...   \n",
       "399996  Matatandaang idiniskwalipika ng Commission on ...   \n",
       "399997  Dahil sa huling score, inilarawan ng Heritage ...   \n",
       "399998  MANILA, Philippines -- Wala umanong karapatan ...   \n",
       "399999  Malinaw aniya na nakasaad sa Section 5, Articl...   \n",
       "\n",
       "                                                       en  \n",
       "0       According to Bayan Muna Rep. Carlos Zarate, Ch...  \n",
       "1       According to the Philippine Embassy in Washing...  \n",
       "2       How do ordinary citizens defend themselves fro...  \n",
       "3                                          SM by the bay   \n",
       "4       Manila, Philippines - The Department of Interi...  \n",
       "...                                                   ...  \n",
       "399995  \"The President Will Discuss With Japanese Prim...  \n",
       "399996  The Commission on Elections (COMELEC) (COMELEC...  \n",
       "399997  Due to the last score, the Heritage Foundation...  \n",
       "399998  Manila, Philippines - The Government of Puerto...  \n",
       "399999  It is clearly stated in Section 5, Article 99 ...  \n",
       "\n",
       "[400000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62307383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Hindi ko ugali ang mamulitika; mas gusto kong...</td>\n",
       "      <td>Ito ang dineklara ni Atty. Romulo Macalintal, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ayon naman kay Bayan Muna Rep. Carlos Zarate, ...</td>\n",
       "      <td>Dating itinutulak ni Duterte ang pagbabago ng ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ayon naman sa Philippine Embassy sa Washington...</td>\n",
       "      <td>Ayon sa NBI, hindi umano siyento por siyentong...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Paano maipagtatanggol ng mga ordinaryong mamam...</td>\n",
       "      <td>\"Nakasaad sa R.A. 9009 na dapat mayroong land ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SM by the bay</td>\n",
       "      <td>Kabilang sa mga sumali sa programang ito ang m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419995</th>\n",
       "      <td>2p.m. Arellano University vs Hog's Breath Cafe</td>\n",
       "      <td>Inirekomenda sa Pangulo ni Albay Rep. Joey Sal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419996</th>\n",
       "      <td>Jason Davee: We rather want the senate head to...</td>\n",
       "      <td>Sabi naman ni Eberl, gumagana pa rin naman uma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419997</th>\n",
       "      <td>Ipinatupad ang liquid ban sa mga istasyon ng M...</td>\n",
       "      <td>Gumastos naman ng P11.587 milyon ang mga contr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419998</th>\n",
       "      <td>Team Standings: zArellano (13-4); zSan Beda (1...</td>\n",
       "      <td>z - Final Four twice-to-beat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419999</th>\n",
       "      <td>Batay sa nakalap na report mula sa tanggapan n...</td>\n",
       "      <td>Hindi umano na-impress si Pangulong Rodrigo Du...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       s1  \\\n",
       "0       \"Hindi ko ugali ang mamulitika; mas gusto kong...   \n",
       "1       Ayon naman kay Bayan Muna Rep. Carlos Zarate, ...   \n",
       "2       Ayon naman sa Philippine Embassy sa Washington...   \n",
       "3       Paano maipagtatanggol ng mga ordinaryong mamam...   \n",
       "4                                           SM by the bay   \n",
       "...                                                   ...   \n",
       "419995     2p.m. Arellano University vs Hog's Breath Cafe   \n",
       "419996  Jason Davee: We rather want the senate head to...   \n",
       "419997  Ipinatupad ang liquid ban sa mga istasyon ng M...   \n",
       "419998  Team Standings: zArellano (13-4); zSan Beda (1...   \n",
       "419999  Batay sa nakalap na report mula sa tanggapan n...   \n",
       "\n",
       "                                                       s2  label  \n",
       "0       Ito ang dineklara ni Atty. Romulo Macalintal, ...      1  \n",
       "1       Dating itinutulak ni Duterte ang pagbabago ng ...      0  \n",
       "2       Ayon sa NBI, hindi umano siyento por siyentong...      1  \n",
       "3       \"Nakasaad sa R.A. 9009 na dapat mayroong land ...      1  \n",
       "4       Kabilang sa mga sumali sa programang ito ang m...      1  \n",
       "...                                                   ...    ...  \n",
       "419995  Inirekomenda sa Pangulo ni Albay Rep. Joey Sal...      1  \n",
       "419996  Sabi naman ni Eberl, gumagana pa rin naman uma...      1  \n",
       "419997  Gumastos naman ng P11.587 milyon ang mga contr...      1  \n",
       "419998                       z - Final Four twice-to-beat      0  \n",
       "419999  Hindi umano na-impress si Pangulong Rodrigo Du...      1  \n",
       "\n",
       "[420000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aff508bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.datasets import ParallelSentencesDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import SentencesDataset, losses, evaluation, readers\n",
    "\n",
    "\n",
    "###### Load train sets ######\n",
    "\n",
    "train_reader = ParallelSentencesDataset(student_model=model, teacher_model=teacher_model)\n",
    "train_reader.add_dataset(df1.values.tolist())\n",
    "#load_data('translate_s1.txt', encoding= 'unicode_escape')\n",
    "train_dataloader = DataLoader(train_reader, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.MSELoss(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1aaa729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e2921a4021c4170917aa7610f07acc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###### Load test sets Mean Squared Error (MSE) measures ######\n",
    "\n",
    "evaluators = []\n",
    "\n",
    "test_mse = evaluation.MSEEvaluator(df1['en'].values.tolist(),df1['tl'].values.tolist(), teacher_model=teacher_model, batch_size=train_batch_size, show_progress_bar=True, write_csv = True)\n",
    "evaluators.append(test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50fe240b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Load dev sets for Semantic Textual Similarity (STS) data ######\n",
    "\n",
    "evaluator_sts = evaluation.EmbeddingSimilarityEvaluator(df2['s1'], df2['s2'], df2['label'], batch_size=train_batch_size, show_progress_bar=True, write_csv=True)\n",
    "evaluators.append(evaluator_sts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b811310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "#gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#print(gpus)\n",
    "\n",
    "#tf.config.set_visible_devices([], 'CPU') # hide the CPU\n",
    "#tf.config.set_visible_devices(gpus[0], 'GPU') # unhide potentially hidden GPU\n",
    "#tf.config.set_visible_devices(gpus[1], 'GPU') # unhide potentially hidden GPU\n",
    "#tf.config.set_visible_devices(gpus[2], 'GPU') # unhide potentially hidden GPU\n",
    "#tf.config.set_visible_devices(gpus[3], 'GPU') # unhide potentially hidden GPU\n",
    "\n",
    "#tf.config.get_visible_devices()\n",
    "\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "gpus = tf.config.list_logical_devices('GPU')\n",
    "strategy = tf.distribute.MirroredStrategy(gpus)\n",
    "tf.config.get_visible_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe6459e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de3ea4e3c8be45fab071cb93b1f0b5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a18d9fe9e3384f4d8e35617dfb4b7bcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/3044 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:537: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_new.cpp:201.)\n",
      "  labels = torch.tensor(labels).to(self._target_device)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7afe5d0378b74b2ab9238e65dedac5d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###### Train model ######\n",
    "\n",
    "import datetime\n",
    "\n",
    "#from numba import jit, cuda, numba\n",
    "\n",
    "#@cuda.jit\n",
    "\n",
    "#with tf.device(\"/gpu:3\"):\n",
    "with strategy.scope():\n",
    "    output_path = \"output/model-\" + datetime.date.today().strftime(\"%Y-%m-%d\")\n",
    "    model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          evaluator=evaluation.SequentialEvaluator(evaluators, main_score_function=lambda scores: scores[-1]),\n",
    "          epochs=100,\n",
    "          evaluation_steps=1000,\n",
    "          warmup_steps=10000,\n",
    "          scheduler='warmupconstant',\n",
    "          output_path=output_path,\n",
    "          save_best_model=True,\n",
    "          optimizer_params= {'lr': 2e-5, 'eps': 1e-6, 'correct_bias': False}\n",
    "          )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848b7d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833591d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.spatial\n",
    "\n",
    "#Corpus with example sentences\n",
    "corpusEN = df3['EN'][:20].values.tolist()\n",
    "corpusTL = df3['TL'][:20].values.tolist()\n",
    "\n",
    "with strategy.scope():\n",
    "    corpusEN_embeddings = model.encode(corpusEN)\n",
    "    corpusTL_embeddings = model.encode(corpusTL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea18f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = df1['EN'][88:89].values.tolist()\n",
    "query_embeddings = model.encode(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd470168",
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_n = 5\n",
    "\n",
    "with strategy.scope():\n",
    "    for query, query_embedding in zip(queries, query_embeddings):\n",
    "        distances = scipy.spatial.distance.cdist([query_embedding], corpusEN_embeddings, \"cosine\")[0]\n",
    "    \n",
    "        results = zip(range(len(distances)), distances)\n",
    "        results = sorted(results, key=lambda x: x[1])\n",
    "    \n",
    "        print(\"\\n=======\\n\")\n",
    "        print(\"Query:\", query)\n",
    "        print(\"\\nTop 5 most similar sentences in corpus:\\n\")\n",
    "\n",
    "        for idx, distance in results[0:closest_n]:\n",
    "            print(corpusEN[idx].strip(), \"(Score: %.4f)\" % (1-distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff0afb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "queriesTL = df1['TL'][88:89].values.tolist()\n",
    "#queriesTL = ['gobyerno.']\n",
    "queryTL_embeddings = model.encode(queriesTL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a6a572",
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_n = 5\n",
    "for query, queryTL_embedding in zip(queriesTL, queryTL_embeddings):\n",
    "    distances = scipy.spatial.distance.cdist([queryTL_embedding], corpusTL_embeddings, \"cosine\")[0]\n",
    "    \n",
    "    results = zip(range(len(distances)), distances)\n",
    "    results = sorted(results, key=lambda x: x[1])\n",
    "    \n",
    "    print(\"\\n=======\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop 5 most similar sentences in corpus:\\n\")\n",
    "\n",
    "    for idx, distance in results[0:closest_n]:\n",
    "        print(corpusTL[idx].strip(), \"(Score: %.4f)\" % (1-distance))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d25f043",
   "metadata": {},
   "source": [
    "### after 100 epocs of training: Query Search Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4437204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.spatial\n",
    "\n",
    "#Corpus with example sentences\n",
    "corpusEN = df3['EN'][:20].values.tolist()\n",
    "corpusTL = df3['TL'][:20].values.tolist()\n",
    "\n",
    "with strategy.scope():\n",
    "    corpusEN_embeddings = model.encode(corpusEN)\n",
    "    corpusTL_embeddings = model.encode(corpusTL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d662593",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = df1['EN'][88:89].values.tolist()\n",
    "query_embeddings = model.encode(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b910d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_n = 5\n",
    "\n",
    "with strategy.scope():\n",
    "    for query, query_embedding in zip(queries, query_embeddings):\n",
    "        distances = scipy.spatial.distance.cdist([query_embedding], corpusEN_embeddings, \"cosine\")[0]\n",
    "    \n",
    "        results = zip(range(len(distances)), distances)\n",
    "        results = sorted(results, key=lambda x: x[1])\n",
    "    \n",
    "        print(\"\\n=======\\n\")\n",
    "        print(\"Query:\", query)\n",
    "        print(\"\\nTop 5 most similar sentences in corpus:\\n\")\n",
    "\n",
    "        for idx, distance in results[0:closest_n]:\n",
    "            print(corpusEN[idx].strip(), \"(Score: %.4f)\" % (1-distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c82325",
   "metadata": {},
   "outputs": [],
   "source": [
    "queriesTL = df1['TL'][88:89].values.tolist()\n",
    "#queriesTL = ['Balita tungkol sa transportasyon, gobyerno ng Pilipinas at iba pa.']\n",
    "queryTL_embeddings = model.encode(queriesTL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cbf953",
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_n = 5\n",
    "for query, queryTL_embedding in zip(queriesTL, queryTL_embeddings):\n",
    "    distances = scipy.spatial.distance.cdist([queryTL_embedding], corpusTL_embeddings, \"cosine\")[0]\n",
    "    \n",
    "    results = zip(range(len(distances)), distances)\n",
    "    results = sorted(results, key=lambda x: x[1])\n",
    "    \n",
    "    print(\"\\n=======\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop 5 most similar sentences in corpus:\\n\")\n",
    "\n",
    "    for idx, distance in results[0:closest_n]:\n",
    "        print(corpusTL[idx].strip(), \"(Score: %.4f)\" % (1-distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3a3dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
